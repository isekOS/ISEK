<!DOCTYPE html>
<html lang="English"
      data-content_root="../../../"
      x-data="{ darkMode: localStorage.getItem('darkMode') || localStorage.setItem('darkMode', 'system'), activeSection: '' }"
      x-init="$watch('darkMode', val => localStorage.setItem('darkMode', val))"
      class="scroll-smooth"
      :class="{'dark': darkMode === 'dark' || (darkMode === 'system' && window.matchMedia('(prefers-color-scheme: dark)').matches)}"
>
<head>
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta charset="utf-8" />
  <meta name="theme-color" media="(prefers-color-scheme: light)" content="white" />
  <meta name="theme-color" media="(prefers-color-scheme: dark)" content="black" />
  
    <title>isek.llm.openai_model | ISEK 0.1 documentation</title>
    <meta property="og:title" content="isek.llm.openai_model | ISEK 0.1 documentation" />
    <meta name="twitter:title" content="isek.llm.openai_model | ISEK 0.1 documentation" />
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=e72c8e07" />
      <link rel="stylesheet" type="text/css" href="../../../_static/theme.css?v=42baaae4" />
        <link rel="search" title="Search" href="../../../search.html" />
        <link rel="index" title="Index" href="../../../genindex.html" />

    <script>
    <!-- Prevent Flash of wrong theme -->
      const userPreference = localStorage.getItem('darkMode');
      let mode;
      if (userPreference === 'dark' || window.matchMedia('(prefers-color-scheme: dark)').matches) {
        mode = 'dark';
        document.documentElement.classList.add('dark');
      } else {
        mode = 'light';
      }
      if (!userPreference) {localStorage.setItem('darkMode', mode)}
    </script>
</head>
  <body x-data="{ showSidebar: false, showScrollTop: false }" class="min-h-screen font-sans antialiased bg-background text-foreground" :class="{ 'overflow-hidden': showSidebar }">
    <div x-cloak x-show="showSidebar" class="fixed inset-0 z-50 overflow-hidden bg-background/80 backdrop-blur-sm md:hidden" @click.self="showSidebar = false"></div><div id="page" class="relative flex flex-col min-h-screen"><a href="#content" class="absolute top-0 left-0 z-[100] block bg-background p-4 text-xl transition -translate-x-full opacity-0 focus:translate-x-0 focus:opacity-100">
      Skip to content
    </a><header
  class="sticky top-0 z-40 w-full border-b shadow-sm border-border supports-backdrop-blur:bg-background/60 bg-background/95 backdrop-blur"><div class="container flex items-center h-14">
    <div class="hidden mr-4 md:flex">
      <a href="../../../index.html" class="flex items-center mr-6"><span class="hidden font-bold sm:inline-block text-clip whitespace-nowrap">ISEK 0.1 documentation</span>
      </a></div><button
      class="inline-flex items-center justify-center h-10 px-0 py-2 mr-2 text-base font-medium transition-colors rounded-md hover:text-accent-foreground hover:bg-transparent md:hidden"
      type="button" @click="showSidebar = true">
      <svg xmlns="http://www.w3.org/2000/svg" height="24" width="24" viewBox="0 96 960 960" aria-hidden="true"
        fill="currentColor">
        <path
          d="M152.587 825.087q-19.152 0-32.326-13.174t-13.174-32.326q0-19.152 13.174-32.326t32.326-13.174h440q19.152 0 32.326 13.174t13.174 32.326q0 19.152-13.174 32.326t-32.326 13.174h-440Zm0-203.587q-19.152 0-32.326-13.174T107.087 576q0-19.152 13.174-32.326t32.326-13.174h320q19.152 0 32.326 13.174T518.087 576q0 19.152-13.174 32.326T472.587 621.5h-320Zm0-203.587q-19.152 0-32.326-13.174t-13.174-32.326q0-19.152 13.174-32.326t32.326-13.174h440q19.152 0 32.326 13.174t13.174 32.326q0 19.152-13.174 32.326t-32.326 13.174h-440ZM708.913 576l112.174 112.174q12.674 12.674 12.674 31.826t-12.674 31.826Q808.413 764.5 789.261 764.5t-31.826-12.674l-144-144Q600 594.391 600 576t13.435-31.826l144-144q12.674-12.674 31.826-12.674t31.826 12.674q12.674 12.674 12.674 31.826t-12.674 31.826L708.913 576Z" />
      </svg>
      <span class="sr-only">Toggle navigation menu</span>
    </button>
    <div class="flex items-center justify-between flex-1 space-x-2 sm:space-x-4 md:justify-end">
      <div class="flex-1 w-full md:w-auto md:flex-none"><form id="searchbox"
      action="../../../search.html"
      method="get"
      class="relative flex items-center group"
      @keydown.k.window.meta="$refs.search.focus()">
  <input x-ref="search"
          name="q"
          id="search-input"
          type="search"
          aria-label="Search the docs"
          placeholder="Search ..."
          class="inline-flex items-center font-medium transition-colors bg-transparent focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 ring-offset-background border border-input hover:bg-accent focus:bg-accent hover:text-accent-foreground focus:text-accent-foreground hover:placeholder-accent-foreground py-2 px-4 relative h-9 w-full justify-start rounded-[0.5rem] text-sm text-muted-foreground sm:pr-12 md:w-40 lg:w-64" />
  <kbd class="pointer-events-none absolute right-1.5 top-2 hidden h-5 select-none text-muted-foreground items-center gap-1 rounded border border-border bg-muted px-1.5 font-mono text-[10px] font-medium opacity-100 sm:flex group-hover:bg-accent group-hover:text-accent-foreground">
    <span class="text-xs">âŒ˜</span>
    K
  </kbd>
</form>
      </div>
      <nav class="flex items-center space-x-1">
        <button @click="darkMode = darkMode === 'light' ? 'dark' : 'light'"
          class="relative inline-flex items-center justify-center px-0 text-sm font-medium transition-colors rounded-md hover:bg-accent hover:text-accent-foreground h-9 w-9"
          type="button"
          aria-label="Color theme switcher">
          <svg xmlns="http://www.w3.org/2000/svg" height="24" width="24" viewBox="0 96 960 960" fill="currentColor"
            class="absolute transition-all scale-100 rotate-0 dark:-rotate-90 dark:scale-0">
            <path
              d="M480 685q45.456 0 77.228-31.772Q589 621.456 589 576q0-45.456-31.772-77.228Q525.456 467 480 467q-45.456 0-77.228 31.772Q371 530.544 371 576q0 45.456 31.772 77.228Q434.544 685 480 685Zm0 91q-83 0-141.5-58.5T280 576q0-83 58.5-141.5T480 376q83 0 141.5 58.5T680 576q0 83-58.5 141.5T480 776ZM80 621.5q-19.152 0-32.326-13.174T34.5 576q0-19.152 13.174-32.326T80 530.5h80q19.152 0 32.326 13.174T205.5 576q0 19.152-13.174 32.326T160 621.5H80Zm720 0q-19.152 0-32.326-13.174T754.5 576q0-19.152 13.174-32.326T800 530.5h80q19.152 0 32.326 13.174T925.5 576q0 19.152-13.174 32.326T880 621.5h-80Zm-320-320q-19.152 0-32.326-13.174T434.5 256v-80q0-19.152 13.174-32.326T480 130.5q19.152 0 32.326 13.174T525.5 176v80q0 19.152-13.174 32.326T480 301.5Zm0 720q-19.152 0-32.326-13.17Q434.5 995.152 434.5 976v-80q0-19.152 13.174-32.326T480 850.5q19.152 0 32.326 13.174T525.5 896v80q0 19.152-13.174 32.33-13.174 13.17-32.326 13.17ZM222.174 382.065l-43-42Q165.5 327.391 166 308.239t13.174-33.065q13.435-13.674 32.587-13.674t32.065 13.674l42.239 43q12.674 13.435 12.555 31.706-.12 18.272-12.555 31.946-12.674 13.674-31.445 13.413-18.772-.261-32.446-13.174Zm494 494.761-42.239-43q-12.674-13.435-12.674-32.087t12.674-31.565Q686.609 756.5 705.38 757q18.772.5 32.446 13.174l43 41.761Q794.5 824.609 794 843.761t-13.174 33.065Q767.391 890.5 748.239 890.5t-32.065-13.674Zm-42-494.761Q660.5 369.391 661 350.62q.5-18.772 13.174-32.446l41.761-43Q728.609 261.5 747.761 262t33.065 13.174q13.674 13.435 13.674 32.587t-13.674 32.065l-43 42.239q-13.435 12.674-31.706 12.555-18.272-.12-31.946-12.555Zm-495 494.761Q165.5 863.391 165.5 844.239t13.674-32.065l43-42.239q13.435-12.674 32.087-12.674t31.565 12.674Q299.5 782.609 299 801.38q-.5 18.772-13.174 32.446l-41.761 43Q231.391 890.5 212.239 890t-33.065-13.174ZM480 576Z" />
          </svg>
          <svg xmlns="http://www.w3.org/2000/svg" height="24" width="24" viewBox="0 96 960 960" fill="currentColor"
            class="absolute transition-all scale-0 rotate-90 dark:rotate-0 dark:scale-100">
            <path
              d="M480 936q-151 0-255.5-104.5T120 576q0-138 90-239.5T440 218q25-3 39 18t-1 44q-17 26-25.5 55t-8.5 61q0 90 63 153t153 63q31 0 61.5-9t54.5-25q21-14 43-1.5t19 39.5q-14 138-117.5 229T480 936Zm0-80q88 0 158-48.5T740 681q-20 5-40 8t-40 3q-123 0-209.5-86.5T364 396q0-20 3-40t8-40q-78 32-126.5 102T200 576q0 116 82 198t198 82Zm-10-270Z" />
          </svg>
        </button>
      </nav>
    </div>
  </div>
</header>

    <div class="flex-1"><div class="container flex-1 items-start md:grid md:grid-cols-[220px_minmax(0,1fr)] md:gap-6 lg:grid-cols-[240px_minmax(0,1fr)] lg:gap-10"><aside id="left-sidebar"
  class="fixed inset-y-0 left-0 md:top-14 z-50 md:z-30 bg-background md:bg-transparent transition-all duration-100 -translate-x-full md:translate-x-0 ml-0 p-6 md:p-0 md:-ml-2 md:h-[calc(100vh-3.5rem)] w-5/6 md:w-full shrink-0 overflow-y-auto border-r border-border md:sticky"
  :aria-hidden="!showSidebar" :class="{ 'translate-x-0': showSidebar }">

    <a href="../../../index.html" class="!justify-start text-sm md:!hidden bg-background"><span class="font-bold text-clip whitespace-nowrap">ISEK 0.1 documentation</span>
    </a>

    <div class="relative overflow-hidden md:overflow-auto my-4 md:my-0 h-[calc(100vh-8rem)] md:h-auto">
      <div class="overflow-y-auto h-full w-full relative pr-6"><nav class="table w-full min-w-full my-6 lg:my-8">
  <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../quickstart.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../user_guide/index.html">User Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../user_guide/concepts.html">Concepts</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../user_guide/agents.html">Agents</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../user_guide/configuration.html">Configuration</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/index.html">API Reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api/core.html">Core Components</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/agent.html">Agent Module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/llm.html">Large Language Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/embedding.html">Embedding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/node.html">Node</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/util.html">Util</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../contributing.html">Contributing</a></li>
</ul>

</nav>
      </div>
    </div>
    <button type="button" @click="showSidebar = false"
      class="absolute md:hidden right-4 top-4 rounded-sm opacity-70 transition-opacity hover:opacity-100">
      <svg xmlns="http://www.w3.org/2000/svg" height="24" width="24" viewBox="0 96 960 960" fill="currentColor"
        stroke="none" class="h-4 w-4">
        <path
          d="M480 632 284 828q-11 11-28 11t-28-11q-11-11-11-28t11-28l196-196-196-196q-11-11-11-28t11-28q11-11 28-11t28 11l196 196 196-196q11-11 28-11t28 11q11 11 11 28t-11 28L536 576l196 196q11 11 11 28t-11 28q-11 11-28 11t-28-11L480 632Z" />
      </svg>
    </button>
  </aside>
        <main class="relative py-6 lg:gap-10 lg:py-8 xl:grid xl:grid-cols-[1fr_300px]">
<div class="w-full min-w-0 mx-auto">
<nav aria-label="breadcrumbs"
     class="flex items-center mb-4 space-x-1 text-sm text-muted-foreground">
  <a class="overflow-hidden text-ellipsis whitespace-nowrap hover:text-foreground"
     href="../../../index.html">
    <span class="hidden md:inline">ISEK 0.1 documentation</span>
    <svg xmlns="http://www.w3.org/2000/svg"
         height="18"
         width="18"
         viewBox="0 96 960 960"
         aria-label="Home"
         fill="currentColor"
         stroke="none"
         class="md:hidden">
      <path d="M240 856h120V616h240v240h120V496L480 316 240 496v360Zm-80 80V456l320-240 320 240v480H520V696h-80v240H160Zm320-350Z" />
    </svg>
  </a>
  
<div class="mr-1">/</div><a class="hover:text-foreground overflow-hidden text-ellipsis whitespace-nowrap"
       href="../../index.html">Module code</a>
    
<div class="mr-1">/</div><span aria-current="page"
        class="font-medium text-foreground overflow-hidden text-ellipsis whitespace-nowrap">isek.llm.openai_model</span>
</nav>

    <div id="content" role="main">
      <h1>Source code for isek.llm.openai_model</h1><div class="highlight"><pre>
<span></span><code><span id="line-1"><span class="sd">&quot;&quot;&quot;encoding=utf-8&quot;&quot;&quot;</span>
</span><span id="line-2">
</span><span id="line-3"><span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
</span><span id="line-4"><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
</span><span id="line-5"><span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
</span><span id="line-6"><span class="kn">from</span><span class="w"> </span><span class="nn">isek.util.logger</span><span class="w"> </span><span class="kn">import</span> <span class="n">logger</span> <span class="c1"># Assuming logger is configured</span>
</span><span id="line-7"><span class="kn">from</span><span class="w"> </span><span class="nn">isek.llm.abstract_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">AbstractModel</span>
</span><span id="line-8"><span class="kn">from</span><span class="w"> </span><span class="nn">isek.util.tools</span><span class="w"> </span><span class="kn">import</span> <span class="n">function_to_schema</span><span class="p">,</span> <span class="n">load_json_from_chat_response</span> <span class="c1"># Assuming these utilities exist</span>
</span><span id="line-9"><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Union</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Any</span> <span class="c1"># Added Any</span>
</span><span id="line-10"><span class="kn">from</span><span class="w"> </span><span class="nn">openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">OpenAI</span>
</span><span id="line-11"><span class="kn">from</span><span class="w"> </span><span class="nn">openai.types.chat</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatCompletion</span> <span class="c1"># For type hinting the response of `create`</span>
</span><span id="line-12">
</span><span id="line-13"><span class="c1"># Define a type alias for message dictionaries for clarity</span>
</span><span id="line-14"><span class="n">ChatMessage</span> <span class="o">=</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span> <span class="c1"># e.g., {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hello&quot;}</span>
</span><span id="line-15"><span class="n">ToolSchema</span> <span class="o">=</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="c1"># e.g., the schema for a tool/function</span>
</span><span id="line-16">
<div class="viewcode-block" id="OpenAIModel">
<a class="viewcode-back" href="../../../api/llm.html#isek.llm.OpenAIModel">[docs]</a>
</span><span id="line-17"><span class="k">class</span><span class="w"> </span><span class="nc">OpenAIModel</span><span class="p">(</span><span class="n">AbstractModel</span><span class="p">):</span>
</span><span id="line-18"><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="line-19"><span class="sd">    An implementation of :class:`~isek.llm.abstract_model.AbstractModel`</span>
</span><span id="line-20"><span class="sd">    that uses OpenAI&#39;s API for chat completions.</span>
</span><span id="line-21">
</span><span id="line-22"><span class="sd">    This class provides methods to interact with OpenAI&#39;s chat models (like GPT-3.5, GPT-4)</span>
</span><span id="line-23"><span class="sd">    to generate text, JSON objects, and handle tool/function calling.</span>
</span><span id="line-24"><span class="sd">    It handles API key and endpoint configuration, request formatting, and retries.</span>
</span><span id="line-25"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="line-26">
</span><span id="line-27">    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="line-28">            <span class="bp">self</span><span class="p">,</span>
</span><span id="line-29">            <span class="n">model_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="line-30">            <span class="n">api_key</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="line-31">            <span class="n">base_url</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="line-32">    <span class="p">):</span>
</span><span id="line-33"><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="line-34"><span class="sd">        Initializes the OpenAIModel client.</span>
</span><span id="line-35">
</span><span id="line-36"><span class="sd">        Configuration (model name, API key, base URL) is sourced from parameters,</span>
</span><span id="line-37"><span class="sd">        falling back to environment variables (`OPENAI_MODEL_NAME`, `OPENAI_API_KEY`,</span>
</span><span id="line-38"><span class="sd">        `OPENAI_BASE_URL`) if parameters are not provided.</span>
</span><span id="line-39">
</span><span id="line-40"><span class="sd">        :param model_name: The name of the OpenAI chat model to use (e.g., &quot;gpt-3.5-turbo&quot;, &quot;gpt-4&quot;).</span>
</span><span id="line-41"><span class="sd">                           If `None`, defaults to the value of `OPENAI_MODEL_NAME` environment variable,</span>
</span><span id="line-42"><span class="sd">                           or remains `None` if the environment variable is also not set (which might lead</span>
</span><span id="line-43"><span class="sd">                           to errors if not specified before making API calls).</span>
</span><span id="line-44"><span class="sd">        :type model_name: typing.Optional[str]</span>
</span><span id="line-45"><span class="sd">        :param api_key: The OpenAI API key. If `None`, defaults to `OPENAI_API_KEY` environment variable.</span>
</span><span id="line-46"><span class="sd">        :type api_key: typing.Optional[str]</span>
</span><span id="line-47"><span class="sd">        :param base_url: The base URL for the OpenAI API. Useful for proxying or using compatible</span>
</span><span id="line-48"><span class="sd">                         non-OpenAI endpoints. If `None`, defaults to `OPENAI_BASE_URL` environment variable,</span>
</span><span id="line-49"><span class="sd">                         or the default OpenAI API URL if the environment variable is also not set.</span>
</span><span id="line-50"><span class="sd">        :type base_url: typing.Optional[str]</span>
</span><span id="line-51"><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="line-52">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="line-53">        <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">model_name</span> <span class="ow">or</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;OPENAI_MODEL_NAME&quot;</span><span class="p">)</span>
</span><span id="line-54">        <span class="c1"># Ensure model_name is set, otherwise API calls will fail.</span>
</span><span id="line-55">        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="p">:</span>
</span><span id="line-56">            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;OpenAIModel initialized without a model_name. API calls may fail. &quot;</span>
</span><span id="line-57">                           <span class="s2">&quot;Set it via parameter or OPENAI_MODEL_NAME environment variable.&quot;</span><span class="p">)</span>
</span><span id="line-58">            <span class="c1"># Consider raising an error here if a model_name is strictly required at init.</span>
</span><span id="line-59">            <span class="c1"># For now, allowing it to be None and potentially fail later.</span>
</span><span id="line-60">
</span><span id="line-61">        <span class="n">_base_url</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">base_url</span> <span class="ow">or</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;OPENAI_BASE_URL&quot;</span><span class="p">)</span>
</span><span id="line-62">        <span class="n">_api_key</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">api_key</span> <span class="ow">or</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;OPENAI_API_KEY&quot;</span><span class="p">)</span>
</span><span id="line-63">
</span><span id="line-64">        <span class="bp">self</span><span class="o">.</span><span class="n">client</span><span class="p">:</span> <span class="n">OpenAI</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span><span class="n">base_url</span><span class="o">=</span><span class="n">_base_url</span><span class="p">,</span> <span class="n">api_key</span><span class="o">=</span><span class="n">_api_key</span><span class="p">)</span>
</span><span id="line-65">        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;OpenAIModel initialized with model: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="si">}</span><span class="s2">, base_url: </span><span class="si">{</span><span class="n">_base_url</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">_base_url</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">&#39;default&#39;</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="line-66">
<div class="viewcode-block" id="OpenAIModel.generate_json">
<a class="viewcode-back" href="../../../api/llm.html#isek.llm.OpenAIModel.generate_json">[docs]</a>
</span><span id="line-67">    <span class="k">def</span><span class="w"> </span><span class="nf">generate_json</span><span class="p">(</span>
</span><span id="line-68">        <span class="bp">self</span><span class="p">,</span>
</span><span id="line-69">        <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="line-70">        <span class="n">system_messages</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">ChatMessage</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="line-71">        <span class="n">retry</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
</span><span id="line-72">        <span class="n">check_json_def</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> <span class="kc">None</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="line-73">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
</span><span id="line-74"><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="line-75"><span class="sd">        Generates a JSON object from the model based on a prompt.</span>
</span><span id="line-76">
</span><span id="line-77"><span class="sd">        It attempts to parse the model&#39;s response content as JSON.</span>
</span><span id="line-78"><span class="sd">        Includes retry logic and an optional validation function for the parsed JSON.</span>
</span><span id="line-79">
</span><span id="line-80"><span class="sd">        .. note::</span>
</span><span id="line-81"><span class="sd">            To reliably get JSON output, ensure your prompt explicitly instructs</span>
</span><span id="line-82"><span class="sd">            the model to generate JSON. Newer OpenAI models support a `response_format`</span>
</span><span id="line-83"><span class="sd">            parameter (e.g., `{&quot;type&quot;: &quot;json_object&quot;}`) in the `create` method,</span>
</span><span id="line-84"><span class="sd">            which could be integrated here for more robust JSON generation.</span>
</span><span id="line-85">
</span><span id="line-86"><span class="sd">        :param prompt: The user prompt instructing the model to generate JSON.</span>
</span><span id="line-87"><span class="sd">        :type prompt: str</span>
</span><span id="line-88"><span class="sd">        :param system_messages: An optional list of system messages to prepend to the conversation.</span>
</span><span id="line-89"><span class="sd">        :type system_messages: typing.Optional[typing.List[ChatMessage]]</span>
</span><span id="line-90"><span class="sd">        :param retry: The number of times to retry the API call if it fails or JSON parsing fails.</span>
</span><span id="line-91"><span class="sd">                      Defaults to 3.</span>
</span><span id="line-92"><span class="sd">        :type retry: int</span>
</span><span id="line-93"><span class="sd">        :param check_json_def: An optional callable that takes the parsed JSON dictionary</span>
</span><span id="line-94"><span class="sd">                               as input and should raise an exception if the JSON is invalid.</span>
</span><span id="line-95"><span class="sd">                               If `None`, no custom validation is performed beyond basic parsing.</span>
</span><span id="line-96"><span class="sd">        :type check_json_def: typing.Optional[typing.Callable[[typing.Dict[str, typing.Any]], None]]</span>
</span><span id="line-97"><span class="sd">        :return: A dictionary parsed from the model&#39;s JSON response.</span>
</span><span id="line-98"><span class="sd">        :rtype: typing.Dict[str, typing.Any]</span>
</span><span id="line-99"><span class="sd">        :raises RuntimeError: If the API call or JSON processing fails after all retries.</span>
</span><span id="line-100"><span class="sd">        :raises ValueError: If JSON parsing fails and `load_json_from_chat_response` also fails.</span>
</span><span id="line-101"><span class="sd">        :raises Exception: If `check_json_def` raises an exception.</span>
</span><span id="line-102"><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="line-103">        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="p">:</span>
</span><span id="line-104">            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;OpenAIModel model_name is not set. Cannot make API calls.&quot;</span><span class="p">)</span>
</span><span id="line-105">
</span><span id="line-106">        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">retry</span><span class="p">):</span>
</span><span id="line-107">            <span class="k">try</span><span class="p">:</span>
</span><span id="line-108">                <span class="c1"># For robust JSON, consider adding response_format={&quot;type&quot;: &quot;json_object&quot;}</span>
</span><span id="line-109">                <span class="c1"># to the `create` call if the model supports it.</span>
</span><span id="line-110">                <span class="c1"># This would require modifying the `create` method or passing it as a kwarg.</span>
</span><span id="line-111">                <span class="n">response</span><span class="p">:</span> <span class="n">ChatCompletion</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
</span><span id="line-112">                    <span class="n">messages</span><span class="o">=</span><span class="p">[{</span><span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;user&#39;</span><span class="p">,</span> <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">}],</span>
</span><span id="line-113">                    <span class="n">systems</span><span class="o">=</span><span class="n">system_messages</span>
</span><span id="line-114">                    <span class="c1"># Example for future: response_format={&quot;type&quot;: &quot;json_object&quot;}</span>
</span><span id="line-115">                <span class="p">)</span>
</span><span id="line-116">                <span class="n">response_content</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span>
</span><span id="line-117">                <span class="k">if</span> <span class="n">response_content</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="line-118">                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Model response content is None.&quot;</span><span class="p">)</span>
</span><span id="line-119">
</span><span id="line-120">                <span class="n">json_result</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span>
</span><span id="line-121">                <span class="k">try</span><span class="p">:</span>
</span><span id="line-122">                    <span class="n">json_result</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">response_content</span><span class="p">)</span>
</span><span id="line-123">                <span class="k">except</span> <span class="n">json</span><span class="o">.</span><span class="n">JSONDecodeError</span><span class="p">:</span>
</span><span id="line-124">                    <span class="c1"># Fallback to a custom JSON extraction logic if direct parsing fails</span>
</span><span id="line-125">                    <span class="n">json_result</span> <span class="o">=</span> <span class="n">load_json_from_chat_response</span><span class="p">(</span><span class="n">response_content</span><span class="p">)</span> <span class="c1"># This must return a dict or raise</span>
</span><span id="line-126">
</span><span id="line-127">                <span class="k">if</span> <span class="n">check_json_def</span><span class="p">:</span>
</span><span id="line-128">                    <span class="n">check_json_def</span><span class="p">(</span><span class="n">json_result</span><span class="p">)</span> <span class="c1"># This function should raise if validation fails</span>
</span><span id="line-129">
</span><span id="line-130">                <span class="k">return</span> <span class="n">json_result</span>
</span><span id="line-131">            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="line-132">                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model [</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="si">}</span><span class="s2">] generate_json attempt </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">retry</span><span class="si">}</span><span class="s2"> failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="line-133">                <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">retry</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span> <span class="c1"># Last attempt</span>
</span><span id="line-134">                    <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;generate_json failed after </span><span class="si">{</span><span class="n">retry</span><span class="si">}</span><span class="s2"> retries for model [</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="si">}</span><span class="s2">].&quot;</span><span class="p">)</span>
</span><span id="line-135">                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to generate valid JSON after </span><span class="si">{</span><span class="n">retry</span><span class="si">}</span><span class="s2"> retries.&quot;</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
</span><span id="line-136">                <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">1</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span> <span class="c1"># Exponential backoff basic</span>
</span><span id="line-137">        <span class="c1"># Should not be reached if retry &gt; 0</span>
</span><span id="line-138">        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;generate_json failed after all retries (unexpectedly reached end of loop).&quot;</span><span class="p">)</span></div>

</span><span id="line-139">
</span><span id="line-140">
<div class="viewcode-block" id="OpenAIModel.generate_text">
<a class="viewcode-back" href="../../../api/llm.html#isek.llm.OpenAIModel.generate_text">[docs]</a>
</span><span id="line-141">    <span class="k">def</span><span class="w"> </span><span class="nf">generate_text</span><span class="p">(</span>
</span><span id="line-142">        <span class="bp">self</span><span class="p">,</span>
</span><span id="line-143">        <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="line-144">        <span class="n">system_messages</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">ChatMessage</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="line-145">        <span class="n">retry</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span>
</span><span id="line-146">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
</span><span id="line-147"><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="line-148"><span class="sd">        Generates plain text from the model based on a prompt.</span>
</span><span id="line-149">
</span><span id="line-150"><span class="sd">        Includes retry logic for API calls.</span>
</span><span id="line-151">
</span><span id="line-152"><span class="sd">        :param prompt: The user prompt for text generation.</span>
</span><span id="line-153"><span class="sd">        :type prompt: str</span>
</span><span id="line-154"><span class="sd">        :param system_messages: An optional list of system messages to prepend.</span>
</span><span id="line-155"><span class="sd">        :type system_messages: typing.Optional[typing.List[ChatMessage]]</span>
</span><span id="line-156"><span class="sd">        :param retry: The number of times to retry the API call if it fails. Defaults to 3.</span>
</span><span id="line-157"><span class="sd">        :type retry: int</span>
</span><span id="line-158"><span class="sd">        :return: The text content generated by the model.</span>
</span><span id="line-159"><span class="sd">        :rtype: str</span>
</span><span id="line-160"><span class="sd">        :raises RuntimeError: If the API call fails after all retries.</span>
</span><span id="line-161"><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="line-162">        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="p">:</span>
</span><span id="line-163">            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;OpenAIModel model_name is not set. Cannot make API calls.&quot;</span><span class="p">)</span>
</span><span id="line-164">
</span><span id="line-165">        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">retry</span><span class="p">):</span>
</span><span id="line-166">            <span class="k">try</span><span class="p">:</span>
</span><span id="line-167">                <span class="n">response</span><span class="p">:</span> <span class="n">ChatCompletion</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
</span><span id="line-168">                    <span class="n">messages</span><span class="o">=</span><span class="p">[{</span><span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;user&#39;</span><span class="p">,</span> <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">}],</span>
</span><span id="line-169">                    <span class="n">systems</span><span class="o">=</span><span class="n">system_messages</span>
</span><span id="line-170">                <span class="p">)</span>
</span><span id="line-171">                <span class="n">response_content</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span>
</span><span id="line-172">                <span class="k">if</span> <span class="n">response_content</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="line-173">                    <span class="c1"># This might happen if the model&#39;s generation is stopped early or filters trigger.</span>
</span><span id="line-174">                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model [</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="si">}</span><span class="s2">] generate_text attempt </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">retry</span><span class="si">}</span><span class="s2"> returned None content.&quot;</span><span class="p">)</span>
</span><span id="line-175">                    <span class="c1"># Depending on requirements, either treat as error or return empty string.</span>
</span><span id="line-176">                    <span class="c1"># For now, let&#39;s try again. If consistently None, the loop will exhaust.</span>
</span><span id="line-177">                    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">retry</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="line-178">                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Model consistently returned None content.&quot;</span><span class="p">)</span>
</span><span id="line-179">                    <span class="k">raise</span> <span class="ne">InterruptedError</span><span class="p">(</span><span class="s2">&quot;Model returned None content, retrying.&quot;</span><span class="p">)</span> <span class="c1"># Custom signal to retry</span>
</span><span id="line-180">                <span class="k">return</span> <span class="n">response_content</span>
</span><span id="line-181">            <span class="k">except</span> <span class="ne">InterruptedError</span><span class="p">:</span> <span class="c1"># Catch the signal to retry specifically for None content</span>
</span><span id="line-182">                <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">retry</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
</span><span id="line-183">                    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">1</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
</span><span id="line-184">                    <span class="k">continue</span>
</span><span id="line-185">                <span class="c1"># If it&#39;s the last retry and still None, it will fall through to the general exception.</span>
</span><span id="line-186">            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="line-187">                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model [</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="si">}</span><span class="s2">] generate_text attempt </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">retry</span><span class="si">}</span><span class="s2"> failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="line-188">                <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">retry</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span> <span class="c1"># Last attempt</span>
</span><span id="line-189">                    <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;generate_text failed after </span><span class="si">{</span><span class="n">retry</span><span class="si">}</span><span class="s2"> retries for model [</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="si">}</span><span class="s2">].&quot;</span><span class="p">)</span>
</span><span id="line-190">                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to generate text after </span><span class="si">{</span><span class="n">retry</span><span class="si">}</span><span class="s2"> retries.&quot;</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
</span><span id="line-191">                <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">1</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span> <span class="c1"># Exponential backoff basic</span>
</span><span id="line-192">        <span class="c1"># Should not be reached if retry &gt; 0</span>
</span><span id="line-193">        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;generate_text failed after all retries (unexpectedly reached end of loop).&quot;</span><span class="p">)</span></div>

</span><span id="line-194">
<div class="viewcode-block" id="OpenAIModel.create">
<a class="viewcode-back" href="../../../api/llm.html#isek.llm.OpenAIModel.create">[docs]</a>
</span><span id="line-195">    <span class="k">def</span><span class="w"> </span><span class="nf">create</span><span class="p">(</span>
</span><span id="line-196">            <span class="bp">self</span><span class="p">,</span>
</span><span id="line-197">            <span class="n">messages</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">ChatMessage</span><span class="p">],</span>
</span><span id="line-198">            <span class="n">systems</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">ChatMessage</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="line-199">            <span class="n">tool_schemas</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">ToolSchema</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="line-200">            <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span> <span class="c1"># Allow passing other ChatCompletion.create parameters</span>
</span><span id="line-201">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ChatCompletion</span><span class="p">:</span>
</span><span id="line-202"><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="line-203"><span class="sd">        Creates a chat completion using the OpenAI API.</span>
</span><span id="line-204">
</span><span id="line-205"><span class="sd">        This is the core method for interacting with the chat model. It can handle</span>
</span><span id="line-206"><span class="sd">        system messages, user/assistant messages, and tool/function schemas.</span>
</span><span id="line-207">
</span><span id="line-208"><span class="sd">        :param messages: A list of message objects, where each object has a &quot;role&quot;</span>
</span><span id="line-209"><span class="sd">                         (e.g., &quot;user&quot;, &quot;assistant&quot;, &quot;tool&quot;) and &quot;content&quot;.</span>
</span><span id="line-210"><span class="sd">        :type messages: typing.List[ChatMessage]</span>
</span><span id="line-211"><span class="sd">        :param systems: An optional list of system message objects. These are typically</span>
</span><span id="line-212"><span class="sd">                        prepended to the `messages` list.</span>
</span><span id="line-213"><span class="sd">        :type systems: typing.Optional[typing.List[ChatMessage]]</span>
</span><span id="line-214"><span class="sd">        :param tool_schemas: An optional list of tool schemas that the model can choose to call.</span>
</span><span id="line-215"><span class="sd">        :type tool_schemas: typing.Optional[typing.List[ToolSchema]]</span>
</span><span id="line-216"><span class="sd">        :param kwargs: Additional keyword arguments to pass directly to the</span>
</span><span id="line-217"><span class="sd">                       `openai.chat.completions.create` method (e.g., `temperature`,</span>
</span><span id="line-218"><span class="sd">                       `max_tokens`, `response_format`).</span>
</span><span id="line-219"><span class="sd">        :type kwargs: typing.Any</span>
</span><span id="line-220"><span class="sd">        :return: The raw ChatCompletion object from the OpenAI API.</span>
</span><span id="line-221"><span class="sd">        :rtype: openai.types.chat.ChatCompletion</span>
</span><span id="line-222"><span class="sd">        :raises openai.APIError: If the OpenAI API returns an error.</span>
</span><span id="line-223"><span class="sd">        :raises ValueError: If `model_name` is not set.</span>
</span><span id="line-224"><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="line-225">        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="p">:</span>
</span><span id="line-226">            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;OpenAIModel model_name is not set. Cannot make API calls.&quot;</span><span class="p">)</span>
</span><span id="line-227">
</span><span id="line-228">        <span class="c1"># Prepend system messages if provided</span>
</span><span id="line-229">        <span class="n">final_messages</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">ChatMessage</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">systems</span> <span class="k">if</span> <span class="n">systems</span> <span class="k">else</span> <span class="p">[])</span> <span class="o">+</span> <span class="n">messages</span>
</span><span id="line-230">
</span><span id="line-231">        <span class="c1"># Filter out None for tool_schemas if it&#39;s explicitly passed as None</span>
</span><span id="line-232">        <span class="n">api_tools</span> <span class="o">=</span> <span class="n">tool_schemas</span> <span class="k">if</span> <span class="n">tool_schemas</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span> <span class="c1"># Pass None if empty, not an empty list</span>
</span><span id="line-233">
</span><span id="line-234">        <span class="n">request_params</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="line-235">            <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="p">,</span>
</span><span id="line-236">            <span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="n">final_messages</span><span class="p">,</span>
</span><span id="line-237">        <span class="p">}</span>
</span><span id="line-238">        <span class="k">if</span> <span class="n">api_tools</span><span class="p">:</span>
</span><span id="line-239">            <span class="n">request_params</span><span class="p">[</span><span class="s2">&quot;tools&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">api_tools</span>
</span><span id="line-240">        
</span><span id="line-241">        <span class="c1"># Merge any additional kwargs</span>
</span><span id="line-242">        <span class="n">request_params</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="line-243">
</span><span id="line-244">        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Request to model [</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="si">}</span><span class="s2">]: </span><span class="si">{</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">request_params</span><span class="p">,</span><span class="w"> </span><span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="n">default</span><span class="o">=</span><span class="nb">str</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="line-245">        <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
</span><span id="line-246">        <span class="k">try</span><span class="p">:</span>
</span><span id="line-247">            <span class="n">response</span><span class="p">:</span> <span class="n">ChatCompletion</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="o">**</span><span class="n">request_params</span><span class="p">)</span>
</span><span id="line-248">            <span class="n">cost_seconds</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>
</span><span id="line-249">            <span class="c1"># Be cautious logging the full response if it&#39;s very large or contains sensitive data.</span>
</span><span id="line-250">            <span class="c1"># Log relevant parts like usage and finish_reason.</span>
</span><span id="line-251">            <span class="n">response_summary</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="line-252">                <span class="s2">&quot;id&quot;</span><span class="p">:</span> <span class="n">response</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
</span><span id="line-253">                <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="n">response</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
</span><span id="line-254">                <span class="s2">&quot;finish_reason&quot;</span><span class="p">:</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">finish_reason</span> <span class="k">if</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span> <span class="k">else</span> <span class="s2">&quot;N/A&quot;</span><span class="p">,</span>
</span><span id="line-255">                <span class="s2">&quot;usage&quot;</span><span class="p">:</span> <span class="n">response</span><span class="o">.</span><span class="n">usage</span><span class="o">.</span><span class="n">model_dump</span><span class="p">()</span> <span class="k">if</span> <span class="n">response</span><span class="o">.</span><span class="n">usage</span> <span class="k">else</span> <span class="s2">&quot;N/A&quot;</span>
</span><span id="line-256">            <span class="p">}</span>
</span><span id="line-257">            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Response from model [</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="si">}</span><span class="s2">] received in </span><span class="si">{</span><span class="n">cost_seconds</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">s. Summary: </span><span class="si">{</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">response_summary</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="line-258">            <span class="k">return</span> <span class="n">response</span>
</span><span id="line-259">        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="line-260">            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Request to model [</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="si">}</span><span class="s2">] failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">exc_info</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># exc_info for stack trace</span>
</span><span id="line-261">            <span class="k">raise</span> <span class="c1"># Re-raise the original exception to be handled by caller or retry logic</span></div>
</div>

</span></code></pre></div>
    </div></div>
        </main>
      </div>
    </div><footer class="py-6 border-t border-border md:py-0">
    <div class="container flex flex-col items-center justify-between gap-4 md:h-24 md:flex-row">
      <div class="flex flex-col items-center gap-4 px-8 md:flex-row md:gap-2 md:px-0">
        <p class="text-sm leading-loose text-center text-muted-foreground md:text-left">Â© 2025, ISEK Team&nbsp;Built with <a class="font-medium underline underline-offset-4"
    href="https://www.sphinx-doc.org"
    rel="noreferrer">Sphinx 8.1.3</a></p>
</div>
</div>
</footer>
  </div>
  
    <script src="../../../_static/documentation_options.js?v=2ed17a75"></script>
    <script src="../../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script defer="defer" src="../../../_static/theme.js?v=073f68d9"></script>
  
</body>
</html>